Enter the name of the forked simulation (leave blank for base_the_ville_isabella_maria_klaus): base_the_ville_isabella_maria_klaus
Enter the name of the new simulation (last was test31): 32
Note: The agents in this simulation package are computational
constructs powered by generative agents architecture and LLM. We
clarify that these agents lack human-like agency, consciousness,
and independent decision-making.
---
Enter option: Traceback (most recent call last):
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/reverie.py", line 496, in open_server
    rs.start_server(int_count)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/reverie.py", line 390, in start_server
    next_tile, pronunciatio, description = persona.move(
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/persona.py", line 222, in move
    plan = self.plan(maze, personas, new_day, retrieved)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/persona.py", line 148, in plan
    return plan(self, maze, personas, new_day, retrieved)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/cognitive_modules/plan.py", line 985, in plan
    _chat_react(maze, persona, focused_event, reaction_mode, personas)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/cognitive_modules/plan.py", line 868, in _chat_react
    convo, duration_min = generate_convo(maze, init_persona, target_persona)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/cognitive_modules/plan.py", line 282, in generate_convo
    convo = agent_chat_v2(maze, init_persona, target_persona)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/cognitive_modules/converse.py", line 136, in agent_chat_v2
    retrieved = new_retrieve(init_persona, focal_points, 50)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/cognitive_modules/retrieve.py", line 261, in new_retrieve
    recency_out = normalize_dict_floats(recency_out, 0, 1)
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/persona/cognitive_modules/retrieve.py", line 98, in normalize_dict_floats
    min_val = min(val for val in d.values())
ValueError: min() arg is an empty sequence
run 5000
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9ba362760>
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9ba23d580>
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9ba23d0a0>
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9ba3ba580>
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9ba324a90>
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9e21bbeb0>
Events in Perceivdd memory: <persona.memory_structures.associative_memory.ConceptNode object at 0x7fc9e21ac8b0>
name 'use_openai' is not defined
REQUEST ERROR
name 'use_openai' is not defined
REQUEST ERROR
name 'use_openai' is not defined
REQUEST ERROR
name 'use_openai' is not defined
REQUEST ERROR
name 'use_openai' is not defined
REQUEST ERROR
=== persona/prompt_template/v2/decide_to_talk_v2.txt
~~~ persona    ---------------------------------------------------
Isabella Rodriguez 

~~~ gpt_param ----------------------------------------------------
{'engine': 'gpt-3.5-turbo', 'max_tokens': 20, 'temperature': 0, 'top_p': 1, 'stream': False, 'frequency_penalty': 0, 'presence_penalty': 0, 'stop': None} 

~~~ prompt_input    ----------------------------------------------
['Isabella Rodriguez was idle. looking around was idle. Maria Lopez was idle. park garden was idle. Klaus Mueller was idle.  tree was idle. park bushes was idle. \n', 'February 13, 2023, 00:00:20 AM', 'Isabella Rodriguez', 'Klaus Mueller', '', '', 'Isabella Rodriguez is already hiding', 'Klaus Mueller is already searching', 'Isabella Rodriguez', 'Klaus Mueller'] 

~~~ prompt    ----------------------------------------------------
Task -- given context, determine whether the subject will initiate a conversation with another. 
Format: 
Context: []
Question: []
Reasoning: []
Answer in "yes" or "no": []
---
Context: Isabella Rodriguez was idle. looking around was idle. Maria Lopez was idle. park garden was idle. Klaus Mueller was idle.  tree was idle. park bushes was idle. 
 
Right now, it is February 13, 2023, 00:00:20 AM. Isabella Rodriguez and Klaus Mueller last chatted at  about . 
Isabella Rodriguez is already hiding 
Klaus Mueller is already searching 

Question: Would Isabella Rodriguez initiate a conversation with Klaus Mueller? 

Reasoning: Let's think step by step. 

~~~ output    ----------------------------------------------------
yes 

=== END ==========================================================




GNS FUNCTION: <generate_decide_to_talk>
July 23
Focal points in new_retrieve function as input: ['Klaus Mueller']
Focal points added if there are none: ['Klaus Mueller']
Nodes in extract_recency function: []

Recency output in extract_recency function: {}
D in normalize_dict_floats function as input: {}

Error.
Enter option: Traceback (most recent call last):
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/reverie.py", line 666, in <module>
    rs.open_server()
  File "/home/jgrandaa/Desktop/simulacra/reverie/backend_server/reverie.py", line 461, in open_server
    sim_command = input("Enter option: ")
KeyboardInterrupt
